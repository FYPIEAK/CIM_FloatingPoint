{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 77.00578965 -53.42176389]]\n",
      "[[46.03220474]\n",
      " [84.72803782]]\n"
     ]
    }
   ],
   "source": [
    "#向量大小\n",
    "n = 2\n",
    "\n",
    "# 均匀分布\n",
    "a_uniform_distribution = np.random.uniform(low=-100, high=100, size=(1,n)) #9.2E-41~3.38E38\n",
    "b_uniform_distribution = np.random.uniform(low=-100, high=100, size=(n,1))\n",
    "print(a_uniform_distribution)\n",
    "print(b_uniform_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bf16标准乘法\n",
    "def standard_bf16_multiply(a, b):\n",
    "    a_tensor = torch.from_numpy(a)\n",
    "    b_tensor = torch.from_numpy(b)\n",
    "    a_bf16 = a_tensor.to(torch.bfloat16)\n",
    "    b_bf16 = b_tensor.to(torch.bfloat16)\n",
    "    result = torch.mm(a_bf16, b_bf16)\n",
    "    result_bf16 = result.to(torch.bfloat16)\n",
    "    return result_bf16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ReDCIM\n",
    "\n",
    "#向量中元素转化为二进制操作\n",
    "def Modify_tensor(tensor):\n",
    "    bf_list = tensor.detach().numpy().tolist() # 转成numpy变量再转换成list    \n",
    "    binary_array = []\n",
    "\n",
    "    for bf_nums in bf_list:\n",
    "        for bf_num in bf_nums:\n",
    "            float_bytes = struct.pack('>f', bf_num)\n",
    "            byte_array = ''.join(f'{byte:08b}' for byte in float_bytes)\n",
    "            binary_array.append(byte_array)\n",
    "    return binary_array\n",
    "\n",
    "#将有符号二进制数转换为整数\n",
    "def binary_to_signed_int(binary, bit_length):\n",
    "    if binary >= 2**(bit_length - 1):\n",
    "        return binary - 2**bit_length\n",
    "    else:\n",
    "        return binary\n",
    "\n",
    "#运算\n",
    "def ReDCIM_bf16_multiply(a,b):\n",
    "    a_tensor = torch.from_numpy(a)\n",
    "    b_tensor = torch.from_numpy(b)\n",
    "    a_fp32 = a_tensor.float()\n",
    "    b_fp32 = b_tensor.float()\n",
    "    a_modified = Modify_tensor(a_fp32)\n",
    "    b_modified = Modify_tensor(b_fp32)\n",
    "    print(\"a二进制表示: \" + str(a_modified))\n",
    "    print(\"b二进制表示: \" + str(b_modified))\n",
    "\n",
    "    ##预对齐\n",
    "    a_exp = []\n",
    "    for number in a_modified:\n",
    "        extracted_part = number[1:9]\n",
    "        a_exp.append(extracted_part)\n",
    "    a_exp_int = [int(binary, 2) for binary in a_exp]\n",
    "    a_exp_max = max(a_exp_int)\n",
    "    a_difference = [a_exp_max - value for value in a_exp_int]\n",
    "    print(\"a差值：\" + str(a_difference))\n",
    "    print(\"a的指数: \" + str(a_exp))\n",
    "\n",
    "    a_mantissa = []\n",
    "    for number in a_modified:\n",
    "        extracted_part = number[0] + '1' + number [9:15] #输入根据booth编码，舍去尾数最后一位\n",
    "        a_mantissa.append(extracted_part)\n",
    "    print(\"a的尾数 Mantissa+: \" + str(a_mantissa))\n",
    "    \n",
    "    b_exp = []\n",
    "    for number in b_modified:\n",
    "        extracted_part = number[1:9]\n",
    "        b_exp.append(extracted_part)\n",
    "    b_exp_int = [int(binary, 2) for binary in b_exp]\n",
    "    b_exp_max = max(b_exp_int)\n",
    "    b_difference = [b_exp_max - value for value in b_exp_int]\n",
    "    print(\"b差值：\" + str(b_difference))\n",
    "    print(\"b的指数: \" + str(b_exp))\n",
    "\n",
    "    b_mantissa = []\n",
    "    for number in b_modified:\n",
    "        extracted_part = number[0] + '1' + number [9:15] # 权重舍去尾数最后一位，和INT8 匹配\n",
    "        b_mantissa.append(extracted_part)\n",
    "    print(\"b的尾数 Mantissa+: \" + str(b_mantissa))\n",
    "    \n",
    "    a_shifted_mantissa_values = []\n",
    "    a_sign_bits = []\n",
    "    for mant, diff in zip(a_mantissa, a_difference):\n",
    "        sign = int(mant[0], 2)  # 提取符号位\n",
    "        a_sign_bits.append(sign)\n",
    "        value = int(mant[1:], 2) >> diff  #只处理数值部分\n",
    "        a_shifted_mantissa_values.append(value)\n",
    "    print(\"a的尾数 移位后: \" + str(a_shifted_mantissa_values))\n",
    "\n",
    "    b_shifted_mantissa_values = []\n",
    "    b_sign_bits = []\n",
    "    for mant, diff in zip(b_mantissa, b_difference):\n",
    "        sign = int(mant[0], 2)\n",
    "        b_sign_bits.append(sign)\n",
    "        value = int(mant[1:], 2) >> diff\n",
    "        b_shifted_mantissa_values.append(value)\n",
    "    print(\"b的尾数 移位后: \" + str(b_shifted_mantissa_values))\n",
    "\n",
    "    ## 尾数相乘\n",
    "    product_mantissa_values = [a * b for a, b in zip(a_shifted_mantissa_values, b_shifted_mantissa_values)]\n",
    "    formatted_product_mantissa_values = [format(value, '014b') for value in product_mantissa_values]  #高位的0被省略，但是浮点数从高位向下取，因此必须补齐\n",
    "\n",
    "    print(\"formatted_product_mantissa: \" + ', '.join(formatted_product_mantissa_values))\n",
    "\n",
    "    product_mantissa = []\n",
    "    for i in range(len(formatted_product_mantissa_values)):\n",
    "        sign = a_sign_bits[i] ^ b_sign_bits[i]\n",
    "        # 取补码\n",
    "        if sign == 1:\n",
    "            inverted_product_mantissa = ''.join('1' if bit == '0' else '0' for bit in formatted_product_mantissa_values[i])\n",
    "            product = format(int(inverted_product_mantissa, 2) + 1, '014b')\n",
    "            product = '1' + product  # 补符号位\n",
    "        else:\n",
    "            product = '0' + formatted_product_mantissa_values[i] # 补符号位\n",
    "        product_mantissa.append(product)\n",
    "\n",
    "    sum_product_mantissa = sum(int(product, 2) for product in product_mantissa)\n",
    "    sign_bit = (sum_product_mantissa >> (len(product_mantissa[0]) - 1)) & 1\n",
    "    value_bits = sum_product_mantissa & ((1 << (len(product_mantissa[0]) - 1)) - 1)\n",
    "\n",
    "    #转换回原码\n",
    "    if sign_bit == 1:\n",
    "        # 取补码（取反加一）\n",
    "        inverted_value_bits = (~value_bits + 1) & ((1 << (len(product_mantissa[0]) - 1)) - 1)\n",
    "        final_result = inverted_value_bits\n",
    "    else:\n",
    "        final_result = value_bits\n",
    "\n",
    "    final_result_binary = format(final_result, '0{}b'.format(len(product_mantissa[0]) - 1))\n",
    "    print(\"新符号位：\" + str(sign_bit))\n",
    "    print(\"新尾数：\" + str(final_result))\n",
    "\n",
    "    mantissa_val = 0\n",
    "    for i, bit in enumerate(final_result_binary[:9]):\n",
    "        mantissa_val += int(bit) * (2 ** (-i + 1))\n",
    "\n",
    "    print(mantissa_val)\n",
    "    combined_result = ((-1) ** sign_bit) * (2 ** (a_exp_max + b_exp_max - 254)) * mantissa_val\n",
    "    return combined_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hybrid_domain\n",
    "def twos_complement(binary_str):\n",
    "    \"\"\"Convert binary string in two's complement to integer.\"\"\"\n",
    "    if binary_str[0] == '1':  # if the binary number is negative\n",
    "        return -1 * (int(''.join('1' if b == '0' else '0' for b in binary_str), 2) + 1)\n",
    "    else:\n",
    "        return int(binary_str, 2)\n",
    "\n",
    "k = 2\n",
    "#运算\n",
    "def Hybrid_bf16_multiply(a,b):\n",
    "    a_tensor = torch.from_numpy(a)\n",
    "    b_tensor = torch.from_numpy(b)\n",
    "    a_fp32 = a_tensor.float()\n",
    "    b_fp32 = b_tensor.float()\n",
    "    a_modified = Modify_tensor(a_fp32)\n",
    "    b_modified = Modify_tensor(b_fp32)\n",
    "\n",
    "    ##预对齐\n",
    "    a_exp = []\n",
    "    for number in a_modified:\n",
    "        extracted_part = number[1:9]\n",
    "        a_exp.append(extracted_part)\n",
    "    a_exp_int = [int(binary, 2) for binary in a_exp]\n",
    "    a_exp_max = max(a_exp_int)\n",
    "    a_difference = [a_exp_max - value for value in a_exp_int]\n",
    "\n",
    "    a_mantissa = []\n",
    "    for number in a_modified:\n",
    "        if number[0] == '1':\n",
    "            inverted_part ='0' + ''.join('1' if bit == '0' else '0' for bit in number[9:16]) #取反码\n",
    "            complement = format(int(inverted_part, 2) + 1, '08b') #取补码\n",
    "            extracted_part = number[0] + complement #加符号位\n",
    "        else:\n",
    "            extracted_part = number[0] + '1' + number[9:16]\n",
    "        a_mantissa.append(extracted_part)\n",
    "    print(\"a的尾数9b补码: \" + str(a_mantissa))\n",
    "    \n",
    "    b_exp = []\n",
    "    for number in b_modified:\n",
    "        extracted_part = number[1:9]\n",
    "        b_exp.append(extracted_part)\n",
    "    b_exp_int = [int(binary, 2) for binary in b_exp]\n",
    "    b_exp_max = max(b_exp_int)\n",
    "    b_difference = [b_exp_max - value for value in b_exp_int]\n",
    "\n",
    "    b_mantissa = []\n",
    "    for number in b_modified:\n",
    "        if number[0] == '1':\n",
    "            inverted_part ='0' + ''.join('1' if bit == '0' else '0' for bit in number[9:16])\n",
    "            complement = format(int(inverted_part, 2) + 1, '08b') \n",
    "            extracted_part = number[0] + complement\n",
    "        else:\n",
    "            extracted_part = number[0] + '1' + number[9:16]\n",
    "        b_mantissa.append(extracted_part)\n",
    "    print(\"b的尾数9b补码: \" + str(b_mantissa))\n",
    "    \n",
    "    a_shifted_mantissa_values = []\n",
    "    for mant, diff in zip(a_mantissa, a_difference):\n",
    "        sign = int(mant[0], 2)\n",
    "        mant_padded = mant + '0' * k\n",
    "        if diff > 0:\n",
    "            shifted_value_binary = (sign * '1' if sign == 1 else '0') * diff + mant_padded[:-diff]\n",
    "        else:\n",
    "            shifted_value_binary = mant_padded\n",
    "        a_shifted_mantissa_values.append(shifted_value_binary)\n",
    "    print(\"a的尾数 移位扩展后: \" + str(a_shifted_mantissa_values))\n",
    "\n",
    "    b_shifted_mantissa_values = []\n",
    "    for mant, diff in zip(b_mantissa, b_difference):\n",
    "        sign = int(mant[0], 2)\n",
    "        mant_padded = mant + '0' * k\n",
    "        if diff > 0:\n",
    "            shifted_value_binary = (sign * '1' if sign == 1 else '0') * diff + mant_padded[:-diff]\n",
    "        else:\n",
    "            shifted_value_binary = mant_padded\n",
    "        b_shifted_mantissa_values.append(shifted_value_binary)\n",
    "    print(\"b的尾数 移位扩展后: \" + str(b_shifted_mantissa_values))\n",
    "\n",
    "    ## 尾数相乘\n",
    "    product_mantissa = [twos_complement(a) * twos_complement(b) for a, b in zip(a_shifted_mantissa_values, b_shifted_mantissa_values)]\n",
    "    sum_product_mantissa = sum(product_mantissa)\n",
    "    sum_product_mantissa_binary = format(sum_product_mantissa,'023b')#高位的0被省略，但是浮点数从高位向下取，因此必须补齐\n",
    "    sign = 1 if sum_product_mantissa < 0 else 0\n",
    "    if sign == 1:\n",
    "        inverted_value = ~int(sum_product_mantissa_binary, 2) + 1\n",
    "        inverted_value_bits = format(inverted_value, '023b')\n",
    "        final_result = inverted_value_bits[1:]\n",
    "    else:\n",
    "        final_result = sum_product_mantissa_binary[1:]\n",
    "\n",
    "    print(\"新符号位：\" + str(sign))\n",
    "    print(\"新尾数：\" + str(final_result))\n",
    "\n",
    "    mantissa_val = 0\n",
    "    for i, bit in enumerate(final_result):\n",
    "        mantissa_val += int(bit) * (2 ** (-i + 3)) ##正常乘，小数点在MSB-2，带符号乘，小数点在MSB-4\n",
    "\n",
    "    print(mantissa_val)\n",
    "    combined_result = ((-1) ** int(sign)) * (2 ** (a_exp_max + b_exp_max - 254)) * mantissa_val\n",
    "    return combined_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ReDCIM_new\n",
    "#运算\n",
    "def ReDCIM_bf16_multiply_new(a,b):\n",
    "    a_tensor = torch.from_numpy(a)\n",
    "    b_tensor = torch.from_numpy(b)\n",
    "    a_fp32 = a_tensor.float()\n",
    "    b_fp32 = b_tensor.float()\n",
    "    a_modified = Modify_tensor(a_fp32)\n",
    "    b_modified = Modify_tensor(b_fp32)\n",
    "\n",
    "    ##预对齐\n",
    "    a_exp = []\n",
    "    for number in a_modified:\n",
    "        extracted_part = number[1:9]\n",
    "        a_exp.append(extracted_part)\n",
    "    a_exp_int = [int(binary, 2) for binary in a_exp]\n",
    "    a_exp_max = max(a_exp_int)\n",
    "    a_difference = [a_exp_max - value for value in a_exp_int]\n",
    "\n",
    "    a_mantissa = []\n",
    "    for number in a_modified:\n",
    "        if number[0] == '1':\n",
    "            inverted_part ='0' + ''.join('1' if bit == '0' else '0' for bit in number[9:15]) #取反码\n",
    "            complement = format(int(inverted_part, 2) + 1, '07b') #取补码\n",
    "            extracted_part = number[0] + complement #加符号位\n",
    "        else:\n",
    "            extracted_part = number[0] + '1' + number[9:15]\n",
    "        a_mantissa.append(extracted_part)\n",
    "    print(\"a的尾数8b补码: \" + str(a_mantissa))\n",
    "    \n",
    "    b_exp = []\n",
    "    for number in b_modified:\n",
    "        extracted_part = number[1:9]\n",
    "        b_exp.append(extracted_part)\n",
    "    b_exp_int = [int(binary, 2) for binary in b_exp]\n",
    "    b_exp_max = max(b_exp_int)\n",
    "    b_difference = [b_exp_max - value for value in b_exp_int]\n",
    "\n",
    "    b_mantissa = []\n",
    "    for number in b_modified:\n",
    "        if number[0] == '1':\n",
    "            inverted_part ='0' + ''.join('1' if bit == '0' else '0' for bit in number[9:15])\n",
    "            complement = format(int(inverted_part, 2) + 1, '07b') \n",
    "            extracted_part = number[0] + complement\n",
    "        else:\n",
    "            extracted_part = number[0] + '1' + number[9:15]\n",
    "        b_mantissa.append(extracted_part)\n",
    "    print(\"b的尾数8b补码: \" + str(b_mantissa))\n",
    "    \n",
    "    a_shifted_mantissa_values = []\n",
    "    for mant, diff in zip(a_mantissa, a_difference):\n",
    "        sign = int(mant[0], 2)\n",
    "        if diff > 0:\n",
    "            shifted_value_binary = (sign * '1' if sign == 1 else '0') * diff + mant[:-diff]\n",
    "        else:\n",
    "            shifted_value_binary = mant\n",
    "        a_shifted_mantissa_values.append(shifted_value_binary)\n",
    "    print(\"a的尾数 移位扩展后: \" + str(a_shifted_mantissa_values))\n",
    "\n",
    "    b_shifted_mantissa_values = []\n",
    "    for mant, diff in zip(b_mantissa, b_difference):\n",
    "        sign = int(mant[0], 2)\n",
    "        if diff > 0:\n",
    "            shifted_value_binary = (sign * '1' if sign == 1 else '0') * diff + mant[:-diff]\n",
    "        else:\n",
    "            shifted_value_binary = mant\n",
    "        b_shifted_mantissa_values.append(shifted_value_binary)\n",
    "    print(\"b的尾数 移位扩展后: \" + str(b_shifted_mantissa_values))\n",
    "\n",
    "    ## 尾数相乘\n",
    "    # 由于是补码相乘，先进行带有符号位的扩展，即扩展到16位\n",
    "    sum_product_mantissa = 0\n",
    "    for a,b in zip(a_shifted_mantissa_values, b_shifted_mantissa_values):\n",
    "        a_extended = a if a[0] == '0' else '1'*8 + a\n",
    "        b_extended = b if b[0] == '0' else '1'*8 + b\n",
    "        product = bin(int(a_extended, 2) * int(b_extended, 2))\n",
    "        product_17_bits = product[-17:]\n",
    "        print(\"部分积: \" + str(product_17_bits))\n",
    "        sum_product_mantissa += int(product_17_bits, 2)\n",
    "    sum_product_mantissa_binary = format(sum_product_mantissa,'017b')\n",
    "    print(\"尾数：\" + str(sum_product_mantissa_binary))\n",
    "    if sum_product_mantissa_binary[0] == 1 :\n",
    "        inverted_value = ~int(sum_product_mantissa_binary, 2) + 1\n",
    "        inverted_value_bits = format(inverted_value, '017b')\n",
    "        final_result = inverted_value_bits[1:]\n",
    "    else:\n",
    "        final_result = sum_product_mantissa_binary[1:]\n",
    "\n",
    "    print(\"新符号位：\" + str(sum_product_mantissa_binary[0]))\n",
    "    print(\"新尾数：\" + str(final_result))\n",
    "\n",
    "    mantissa_val = 0\n",
    "    for i, bit in enumerate(final_result):\n",
    "        mantissa_val += int(bit) * (2 ** (-i + 3)) ##正常乘，小数点在MSB-2，带符号乘，小数点在MSB-4\n",
    "\n",
    "    print(mantissa_val)\n",
    "    combined_result = ((-1) ** int(sum_product_mantissa_binary[0])) * (2 ** (a_exp_max + b_exp_max - 254)) * mantissa_val\n",
    "    return combined_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result standard:\n",
      " tensor([[-980.]], dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "result_standard = standard_bf16_multiply(a_uniform_distribution, b_uniform_distribution)\n",
    "print(\"Result standard:\\n\", result_standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a的尾数8b补码: ['01001101', '10010110']\n",
      "b的尾数8b补码: ['01011100', '01010100']\n",
      "a的尾数 移位扩展后: ['01001101', '11001011']\n",
      "b的尾数 移位扩展后: ['00101110', '01010100']\n",
      "部分积: 0b110111010110\n",
      "部分积: 11110111010011100\n",
      "尾数：11111110001110010\n",
      "新符号位：1\n",
      "新尾数：1111110001110010\n",
      "15.77783203125\n",
      "Result ReDCIM:\n",
      " -64626.0\n"
     ]
    }
   ],
   "source": [
    "result_ReDCIM = ReDCIM_bf16_multiply_new(a_uniform_distribution, b_uniform_distribution)\n",
    "print(\"Result ReDCIM:\\n\", result_ReDCIM)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a的尾数9b补码: ['010011010', '100101011']\n",
      "b的尾数9b补码: ['010111000', '010101001']\n",
      "a的尾数 移位扩展后: ['01001101000', '11001010110']\n",
      "b的尾数 移位扩展后: ['00101110000', '01010100100']\n",
      "新符号位：1\n",
      "新尾数：0000001110111101101000\n",
      "0.233795166015625\n",
      "result_Hybrid:\n",
      " -957.625\n"
     ]
    }
   ],
   "source": [
    "result_Hybrid = Hybrid_bf16_multiply(a_uniform_distribution, b_uniform_distribution)\n",
    "print(\"result_Hybrid:\\n\", result_Hybrid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
